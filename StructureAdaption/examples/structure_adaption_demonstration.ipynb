{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "StructureAdaptionFramework: a framework for handling neuron-level and layer-level structure adaptions in\n",
    "neural networks.\n",
    "\n",
    "Copyright (C) 2023  Roman Frels, roman.frels@gmail.com\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU Affero General Public License as published by\n",
    "the Free Software Foundation, version 3 of the License.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU Affero General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Affero General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Structure adaption demonstration\n",
    "\n",
    "This is a demonstration of the capabilities of the structure adaption framework. In short, it supports growing and pruning of neurons and (multiple) layers while training the model and handles related tasks for convenience,\n",
    "including preserving all weights and keeping the optimizer slots for the weights intact.\n",
    "It is designed to work in conjunction with growing and pruning criteria that optimize the network architecture during training.\n",
    "\n",
    "First we load a simple image recognition dataset and set up a simple convolutional neural network that we train for one epoch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 21:04:42.066631: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-06 21:04:42.066654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-09-06 21:04:44.019653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-09-06 21:04:44.019675: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-06 21:04:44.019692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rome): /proc/driver/nvidia/version does not exist\n",
      "2023-09-06 21:04:44.019906: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " x0 (InputLayer)             [(None, 60, 60, 3)]       0         \n",
      "                                                                 \n",
      " x1 (AdaptionLayer)          (None, 60, 60, 8)         224       \n",
      "                                                                 \n",
      " x2 (AdaptionLayer)          (None, 60, 60, 8)         32        \n",
      "                                                                 \n",
      " x3 (AdaptionLayer)          (None, 58, 58, 8)         584       \n",
      "                                                                 \n",
      " x4 (AdaptionLayer)          (None, 58, 58, 8)         32        \n",
      "                                                                 \n",
      " x5 (AdaptionLayer)          (None, 29, 29, 8)         584       \n",
      "                                                                 \n",
      " x6 (AdaptionLayer)          (None, 29, 29, 8)         32        \n",
      "                                                                 \n",
      " x7 (AdaptionLayer)          (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " x8 (AdaptionLayer)          (None, 14, 14, 8)         32        \n",
      "                                                                 \n",
      " x9 (Flatten)                (None, 1568)              0         \n",
      "                                                                 \n",
      " x10 (AdaptionLayer)         (None, 12)                18828     \n",
      "                                                                 \n",
      " x11 (AdaptionLayer)         (None, 8)                 104       \n",
      "                                                                 \n",
      " x12 (AdaptionLayer)         (None, 4)                 36        \n",
      "                                                                 \n",
      " x13 (Softmax)               (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,072\n",
      "Trainable params: 21,008\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 1.3910 - sparse_categorical_accuracy: 0.2273\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import StructureAdaption.structure_adaption as structure_adaption\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "num_pixels = 60\n",
    "ds_train = tfds.load('citrus_leaves', shuffle_files=True, as_supervised=True, with_info=False)\n",
    "ds_train = ds_train['train']\n",
    "def resize_image(image, label):\n",
    "    resized_image = tf.image.resize(image, (num_pixels, num_pixels))\n",
    "    return resized_image, label\n",
    "ds_train = ds_train.map(resize_image)\n",
    "ds_train = ds_train.batch(32)\n",
    "\n",
    "def example_model():\n",
    "    inputs = tf.keras.Input(shape=[num_pixels, num_pixels, 3], dtype=tf.dtypes.float32, name='x0')\n",
    "\n",
    "    x1 = tf.keras.layers.Conv2D(8, 3, strides=1, padding='same', activation='relu', name='x1')(inputs)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name='x2')(x1)\n",
    "    x3 = tf.keras.layers.Conv2D(8, 3, strides=1, padding='valid', activation='relu', name='x3')(x2)\n",
    "    x4 = tf.keras.layers.BatchNormalization(name='x4')(x3)\n",
    "    x5 = tf.keras.layers.Conv2D(8, 3, strides=2, padding='same', activation='relu', name='x5')(x4)\n",
    "    x6 = tf.keras.layers.BatchNormalization(name='x6')(x5)\n",
    "    x7 = tf.keras.layers.Conv2D(8, 3, strides=2, padding='valid', activation='relu', name='x7')(x6)\n",
    "    x8 = tf.keras.layers.BatchNormalization(name='x8')(x7)\n",
    "\n",
    "    x9 = tf.keras.layers.Flatten(name='x9')(x8)\n",
    "    x10 = tf.keras.layers.Dense(units=12, activation='relu', name='x10')(x9)\n",
    "    x11 = tf.keras.layers.Dense(units=8, activation='relu', name='x11')(x10)\n",
    "    x12 = tf.keras.layers.Dense(units=4, activation='relu', name='x12')(x11)\n",
    "    outputs = tf.keras.layers.Softmax(name='x13')(x12)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "base_model = example_model()\n",
    "parsed_model = structure_adaption.parse_model(base_model)\n",
    "\n",
    "def compile_fn():\n",
    "    parsed_model(tf.random.uniform(shape=(1, num_pixels, num_pixels, 3)))\n",
    "    #parsed_model(tf.keras.Input((num_features)))\n",
    "\n",
    "parsed_model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.01)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "parsed_model.internal_model.compile(optimizer, loss_fn, metrics)\n",
    "parsed_model.internal_model.fit(ds_train, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-06T21:04:41.870999Z",
     "end_time": "2023-09-06T21:04:46.879738Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since this is a simple sequential model, a growing criterion might choose to open a parallel branch convolutional layers with larger receptive fields. Keep in mind that all kinds of complicated structures would be possible, whatever the criterion chooses.\n",
    "We introduce new layers and connect them to the insert start layer x2. The insert branch ends at layer x7, where a new add layer will be introduced. Observe the new layer in the summary named `new_add_node0`. After growing the branch the internal model is\n",
    "recompiled with the optimizer, loss function and metrics and the training is continued. To get a better understanding of the framework it is important to understand that the internal tensorflow model is copied with each adaption. This invalidates of course\n",
    "all references to the old internal model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of insert branch: x2, end of insert branch: x7\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x0 (InputLayer)                [(None, 60, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " x1 (AdaptionLayer)             (None, 60, 60, 8)    224         ['x0[0][0]']                     \n",
      "                                                                                                  \n",
      " x2 (AdaptionLayer)             (None, 60, 60, 8)    32          ['x1[0][0]']                     \n",
      "                                                                                                  \n",
      " x14 (AdaptionLayer)            (None, 60, 60, 8)    1608        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x16 (AdaptionLayer)            (None, 60, 60, 8)    5192        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x3 (AdaptionLayer)             (None, 58, 58, 8)    584         ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x15 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x14[0][0]']                    \n",
      "                                                                                                  \n",
      " x17 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x16[0][0]']                    \n",
      "                                                                                                  \n",
      " x4 (AdaptionLayer)             (None, 58, 58, 8)    32          ['x3[0][0]']                     \n",
      "                                                                                                  \n",
      " x18 (Add)                      (None, 60, 60, 8)    0           ['x15[0][0]',                    \n",
      "                                                                  'x17[0][0]']                    \n",
      "                                                                                                  \n",
      " x5 (AdaptionLayer)             (None, 29, 29, 8)    584         ['x4[0][0]']                     \n",
      "                                                                                                  \n",
      " x19 (AdaptionLayer)            (None, 29, 29, 8)    584         ['x18[0][0]']                    \n",
      "                                                                                                  \n",
      " x6 (AdaptionLayer)             (None, 29, 29, 8)    32          ['x5[0][0]']                     \n",
      "                                                                                                  \n",
      " x20 (AdaptionLayer)            (None, 29, 29, 8)    32          ['x19[0][0]']                    \n",
      "                                                                                                  \n",
      " new_add_node0 (Add)            (None, 29, 29, 8)    0           ['x6[0][0]',                     \n",
      "                                                                  'x20[0][0]']                    \n",
      "                                                                                                  \n",
      " x7 (AdaptionLayer)             (None, 14, 14, 8)    584         ['new_add_node0[0][0]']          \n",
      "                                                                                                  \n",
      " x8 (AdaptionLayer)             (None, 14, 14, 8)    32          ['x7[0][0]']                     \n",
      "                                                                                                  \n",
      " x9 (Flatten)                   (None, 1568)         0           ['x8[0][0]']                     \n",
      "                                                                                                  \n",
      " x10 (AdaptionLayer)            (None, 12)           18828       ['x9[0][0]']                     \n",
      "                                                                                                  \n",
      " x11 (AdaptionLayer)            (None, 8)            104         ['x10[0][0]']                    \n",
      "                                                                                                  \n",
      " x12 (AdaptionLayer)            (None, 4)            36          ['x11[0][0]']                    \n",
      "                                                                                                  \n",
      " x13 (Softmax)                  (None, 4)            0           ['x12[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,552\n",
      "Trainable params: 28,440\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n",
      "19/19 [==============================] - 7s 326ms/step - loss: 1.3895 - sparse_categorical_accuracy: 0.2290\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f124475bf10>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_start = parsed_model.internal_model.layers[2]\n",
    "insert_end = parsed_model.internal_model.layers[7]\n",
    "print('start of insert branch: ' + insert_start.name + ', end of insert branch: ' + insert_end.name)\n",
    "\n",
    "l14 = tf.keras.layers.Conv2D(8, 5, strides=1, padding='same', activation='relu', name='x14')\n",
    "x14 = l14(insert_start.output)\n",
    "l15 = tf.keras.layers.BatchNormalization(name='x15')\n",
    "x15 = l15(x14)\n",
    "\n",
    "l16 = tf.keras.layers.Conv2D(8, 9, strides=1, padding='same', activation='relu', name='x16')\n",
    "x16 = l16(insert_start.output)\n",
    "l17 = tf.keras.layers.BatchNormalization(name='x17')\n",
    "x17 = l17(x16)\n",
    "\n",
    "l18 = tf.keras.layers.Add(name='x18')\n",
    "x18 = l18([x15, x17])\n",
    "\n",
    "l19 = tf.keras.layers.Conv2D(8, 3, strides=2, padding='valid', activation='relu', name='x19')\n",
    "x19 = l19(x18)\n",
    "l20 = tf.keras.layers.BatchNormalization(name='x20')\n",
    "x20 = l20(x19)\n",
    "\n",
    "insert_branch = structure_adaption.InsertBranch([insert_start, l14, l15, l16, l17, l18, l19, l20], insert_end)\n",
    "parsed_model.grow_branch(insert_branch, optimizer, compile_fn, carry_optimizer=True)\n",
    "parsed_model.summary()\n",
    "parsed_model.internal_model.compile(optimizer, loss_fn, metrics)\n",
    "parsed_model.internal_model.fit(ds_train, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-06T21:04:46.879262Z",
     "end_time": "2023-09-06T21:04:53.774712Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A pruning criterion might choose to remove one of the layers of the classifier head. We select the layer in question (x11), as well as the preceding (x10) and subsequent (x12) layers as start, middle and end of the newly created pruning branch.\n",
    "When pruning the layer `leave_residual=True` is chosen to preserve the connection from start to end of the pruning branch. Furthermore `skip_mismatch=True` is chosen. This allows new weights to be initialized for layer x12,\n",
    "since the old weights expect an input with dimension `[... 8]` but will get dimension `[... 12]`. The training is continued again after the adaption step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start layer: x10, to be removed layer: x11, end layer: x12\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x0 (InputLayer)                [(None, 60, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " x1 (AdaptionLayer)             (None, 60, 60, 8)    224         ['x0[0][0]']                     \n",
      "                                                                                                  \n",
      " x2 (AdaptionLayer)             (None, 60, 60, 8)    32          ['x1[0][0]']                     \n",
      "                                                                                                  \n",
      " x14 (AdaptionLayer)            (None, 60, 60, 8)    1608        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x16 (AdaptionLayer)            (None, 60, 60, 8)    5192        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x3 (AdaptionLayer)             (None, 58, 58, 8)    584         ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x15 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x14[0][0]']                    \n",
      "                                                                                                  \n",
      " x17 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x16[0][0]']                    \n",
      "                                                                                                  \n",
      " x4 (AdaptionLayer)             (None, 58, 58, 8)    32          ['x3[0][0]']                     \n",
      "                                                                                                  \n",
      " x18 (Add)                      (None, 60, 60, 8)    0           ['x15[0][0]',                    \n",
      "                                                                  'x17[0][0]']                    \n",
      "                                                                                                  \n",
      " x5 (AdaptionLayer)             (None, 29, 29, 8)    584         ['x4[0][0]']                     \n",
      "                                                                                                  \n",
      " x19 (AdaptionLayer)            (None, 29, 29, 8)    584         ['x18[0][0]']                    \n",
      "                                                                                                  \n",
      " x6 (AdaptionLayer)             (None, 29, 29, 8)    32          ['x5[0][0]']                     \n",
      "                                                                                                  \n",
      " x20 (AdaptionLayer)            (None, 29, 29, 8)    32          ['x19[0][0]']                    \n",
      "                                                                                                  \n",
      " new_add_node0 (Add)            (None, 29, 29, 8)    0           ['x6[0][0]',                     \n",
      "                                                                  'x20[0][0]']                    \n",
      "                                                                                                  \n",
      " x7 (AdaptionLayer)             (None, 14, 14, 8)    584         ['new_add_node0[0][0]']          \n",
      "                                                                                                  \n",
      " x8 (AdaptionLayer)             (None, 14, 14, 8)    32          ['x7[0][0]']                     \n",
      "                                                                                                  \n",
      " x9 (Flatten)                   (None, 1568)         0           ['x8[0][0]']                     \n",
      "                                                                                                  \n",
      " x10 (AdaptionLayer)            (None, 12)           18828       ['x9[0][0]']                     \n",
      "                                                                                                  \n",
      " x12 (AdaptionLayer)            (None, 4)            52          ['x10[0][0]']                    \n",
      "                                                                                                  \n",
      " x13 (Softmax)                  (None, 4)            0           ['x12[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,464\n",
      "Trainable params: 28,352\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 1.3459 - sparse_categorical_accuracy: 0.2783\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f1244606340>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = parsed_model.internal_model.layers\n",
    "remove_start = layers[18]\n",
    "remove_layer = layers[19]\n",
    "remove_end = layers[20]\n",
    "print('start layer: ' + remove_start.name + ', to be removed layer: ' + remove_layer.name + ', end layer: ' + remove_end.name)\n",
    "remove_branch = structure_adaption.Branch([remove_start, remove_layer, remove_end])\n",
    "parsed_model.prun_branch(remove_branch, optimizer, compile_fn, carry_optimizer=True,leave_residual=True, skip_mismatch=True)\n",
    "parsed_model.summary()\n",
    "\n",
    "parsed_model.internal_model.compile(optimizer, loss_fn, metrics)\n",
    "parsed_model.internal_model.fit(ds_train, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-06T21:04:53.784275Z",
     "end_time": "2023-09-06T21:05:00.536011Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A pruning criterion for neuron-level pruning might choose to remove neurons from the classification layer x10. This is done by retrieving first the grow prun tuples from the parsed model. These contain all valid combinations for neuron-level adaptions.\n",
    "The first contained layer is the layer where neurons are added or remove and the last layer has its input weight adjusted accordingly.\n",
    "Intermediate layers of the grow prun tuple are conserving the output dimension of the previous layer and don't have a notion of neurons.\n",
    "\n",
    "We retrieve the grow prun tuple matching layer x10 and prun four neurons. The training is again continued afterward."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning neurons in layer: x10\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x0 (InputLayer)                [(None, 60, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " x1 (AdaptionLayer)             (None, 60, 60, 8)    224         ['x0[0][0]']                     \n",
      "                                                                                                  \n",
      " x2 (AdaptionLayer)             (None, 60, 60, 8)    32          ['x1[0][0]']                     \n",
      "                                                                                                  \n",
      " x14 (AdaptionLayer)            (None, 60, 60, 8)    1608        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x16 (AdaptionLayer)            (None, 60, 60, 8)    5192        ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x3 (AdaptionLayer)             (None, 58, 58, 8)    584         ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      " x15 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x14[0][0]']                    \n",
      "                                                                                                  \n",
      " x17 (AdaptionLayer)            (None, 60, 60, 8)    32          ['x16[0][0]']                    \n",
      "                                                                                                  \n",
      " x4 (AdaptionLayer)             (None, 58, 58, 8)    32          ['x3[0][0]']                     \n",
      "                                                                                                  \n",
      " x18 (Add)                      (None, 60, 60, 8)    0           ['x15[0][0]',                    \n",
      "                                                                  'x17[0][0]']                    \n",
      "                                                                                                  \n",
      " x5 (AdaptionLayer)             (None, 29, 29, 8)    584         ['x4[0][0]']                     \n",
      "                                                                                                  \n",
      " x19 (AdaptionLayer)            (None, 29, 29, 8)    584         ['x18[0][0]']                    \n",
      "                                                                                                  \n",
      " x6 (AdaptionLayer)             (None, 29, 29, 8)    32          ['x5[0][0]']                     \n",
      "                                                                                                  \n",
      " x20 (AdaptionLayer)            (None, 29, 29, 8)    32          ['x19[0][0]']                    \n",
      "                                                                                                  \n",
      " new_add_node0 (Add)            (None, 29, 29, 8)    0           ['x6[0][0]',                     \n",
      "                                                                  'x20[0][0]']                    \n",
      "                                                                                                  \n",
      " x7 (AdaptionLayer)             (None, 14, 14, 8)    584         ['new_add_node0[0][0]']          \n",
      "                                                                                                  \n",
      " x8 (AdaptionLayer)             (None, 14, 14, 8)    32          ['x7[0][0]']                     \n",
      "                                                                                                  \n",
      " x9 (Flatten)                   (None, 1568)         0           ['x8[0][0]']                     \n",
      "                                                                                                  \n",
      " x10 (AdaptionLayer)            (None, 8)            12552       ['x9[0][0]']                     \n",
      "                                                                                                  \n",
      " x12 (AdaptionLayer)            (None, 4)            36          ['x10[0][0]']                    \n",
      "                                                                                                  \n",
      " x13 (Softmax)                  (None, 4)            0           ['x12[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,172\n",
      "Trainable params: 22,060\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n",
      "19/19 [==============================] - 7s 351ms/step - loss: 1.3032 - sparse_categorical_accuracy: 0.3211\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f12446022e0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_tuples = parsed_model.grow_prun_tuples\n",
    "print('pruning neurons in layer: ' + gp_tuples[1].first_layer.name)\n",
    "parsed_model.prun(gp_tuples[1], [1, 4, 5, 8], optimizer, compile_fn)\n",
    "parsed_model.summary()\n",
    "\n",
    "parsed_model.internal_model.compile(optimizer, loss_fn, metrics)\n",
    "parsed_model.internal_model.fit(ds_train, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-06T21:05:00.540505Z",
     "end_time": "2023-09-06T21:05:08.133990Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A growing criterion for neuron-level pruning might choose to add neurons/filters to the layer x3. For sake of brevity a simple zero initializer is supplied for the newly initialized weights in the first layer, intermediate layer and last layer.\n",
    "However, it should be noted that the newly initialized weights can also be specified with numpy arrays or tensorflow tensors. After growing the model is trained one last time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "growing neurons in layer: x3\n",
      "19/19 [==============================] - 8s 376ms/step - loss: 1.2401 - sparse_categorical_accuracy: 0.3657\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f12442bf2b0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_tuples = parsed_model.grow_prun_tuples\n",
    "print('growing neurons in layer: ' + gp_tuples[0].first_layer.name)\n",
    "zeros_init = tf.keras.initializers.Zeros()\n",
    "init_dict = {'first': [zeros_init, zeros_init], 'intermediate': [[zeros_init, zeros_init, zeros_init, zeros_init]], 'last': [zeros_init, zeros_init]}\n",
    "parsed_model.grow(gp_tuples[0], 2, init_dict, optimizer, compile_fn)\n",
    "\n",
    "parsed_model.internal_model.compile(optimizer, loss_fn, metrics)\n",
    "parsed_model.internal_model.fit(ds_train, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-06T21:05:08.140167Z",
     "end_time": "2023-09-06T21:05:16.680386Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this demonstration layer-level and neuron-level growing and pruning was performed, intermixed with training the model. For all caveats that apply consult the documentation."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
